https://medium.com/rahasak/build-rag-application-using-a-llm-running-on-local-computer-with-ollama-and-llamaindex-97703153db20
	curl http://localhost:11434/api/generate -d '{"model":"llama3",
	"prompt":"What is docker?", "stream":false}'

https://docs.llamaindex.ai/en/stable/module_guides/models/llms/usage_custom/

https://docs.llamaindex.ai/en/stable/api_reference/llms/ollama/
	from llama_index.llms.ollama import Ollama
	llm = Ollama(model="llama3")
	response = llm.complete('What is the capital of Greece?')
	print(response)

https://www.reddit.com/r/ollama/comments/1app5v0/where_would_i_find_the_model_files_on_my_mac/
https://github.com/ollama/ollama/issues/4122
	~/.ollama/models/

-------------------------------------------------

pip install llama-index-embeddings-huggingface


Collecting llama-index-embeddings-huggingface
  Using cached llama_index_embeddings_huggingface-0.2.1-py3-none-any.whl (7.1 kB)
Collecting huggingface-hub[inference]>=0.19.0
  Using cached huggingface_hub-0.23.2-py3-none-any.whl (401 kB)

Collecting llama-index-core<0.11.0,>=0.10.1
  Downloading llama_index_core-0.10.41-py3-none-any.whl (15.4 MB)

Collecting sentence-transformers<3.0.0,>=2.6.1
  Using cached sentence_transformers-2.7.0-py3-none-any.whl (171 kB)
Collecting filelock
  Using cached filelock-3.14.0-py3-none-any.whl (12 kB)
Collecting fsspec>=2023.5.0
  Using cached fsspec-2024.5.0-py3-none-any.whl (316 kB)
Collecting packaging>=20.9
  Using cached packaging-24.0-py3-none-any.whl (53 kB)
Collecting pyyaml>=5.1
  Using cached PyYAML-6.0.1-cp311-cp311-macosx_11_0_arm64.whl (167 kB)
Collecting requests
  Using cached requests-2.32.3-py3-none-any.whl (64 kB)
Collecting tqdm>=4.42.1
  Using cached tqdm-4.66.4-py3-none-any.whl (78 kB)
Collecting typing-extensions>=3.7.4.3
  Using cached typing_extensions-4.12.0-py3-none-any.whl (37 kB)
Collecting aiohttp
  Using cached aiohttp-3.9.5-cp311-cp311-macosx_11_0_arm64.whl (390 kB)
Collecting minijinja>=1.0
  Using cached minijinja-2.0.1-cp38-abi3-macosx_10_12_x86_64.macosx_11_0_arm64.macosx_10_12_universal2.whl (1.6 MB)
Collecting SQLAlchemy[asyncio]>=1.4.49
  Using cached SQLAlchemy-2.0.30-cp311-cp311-macosx_11_0_arm64.whl (2.1 MB)
Collecting dataclasses-json
  Using cached dataclasses_json-0.6.6-py3-none-any.whl (28 kB)
Collecting deprecated>=1.2.9.3
  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)
Collecting dirtyjson<2.0.0,>=1.0.8
  Using cached dirtyjson-1.0.8-py3-none-any.whl (25 kB)
Collecting httpx
  Using cached httpx-0.27.0-py3-none-any.whl (75 kB)
Collecting llamaindex-py-client<0.2.0,>=0.1.18
  Using cached llamaindex_py_client-0.1.19-py3-none-any.whl (141 kB)
Collecting nest-asyncio<2.0.0,>=1.5.8
  Using cached nest_asyncio-1.6.0-py3-none-any.whl (5.2 kB)
Collecting networkx>=3.0
  Using cached networkx-3.3-py3-none-any.whl (1.7 MB)
Collecting nltk<4.0.0,>=3.8.1
  Using cached nltk-3.8.1-py3-none-any.whl (1.5 MB)

Collecting numpy
  Using cached numpy-1.26.4-cp311-cp311-macosx_11_0_arm64.whl (14.0 MB)

Collecting openai>=1.1.0
  Downloading openai-1.30.5-py3-none-any.whl (320 kB)

Collecting pandas
  Using cached pandas-2.2.2-cp311-cp311-macosx_11_0_arm64.whl (11.3 MB)

Collecting pillow>=9.0.0
  Using cached pillow-10.3.0-cp311-cp311-macosx_11_0_arm64.whl (3.4 MB)
Collecting tenacity<9.0.0,>=8.2.0
  Using cached tenacity-8.3.0-py3-none-any.whl (25 kB)
Collecting tiktoken>=0.3.3
  Using cached tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl (907 kB)
Collecting typing-inspect>=0.8.0
  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)
Collecting wrapt
  Using cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)

Collecting transformers<5.0.0,>=4.34.0
  Using cached transformers-4.41.2-py3-none-any.whl (9.1 MB) ---------> this ends up 85 MB

Collecting torch>=1.11.0
  Using cached torch-2.3.0-cp311-none-macosx_11_0_arm64.whl (61.0 MB) ---------> this ends up 290 MB

Collecting scikit-learn
  Using cached scikit_learn-1.5.0-cp311-cp311-macosx_12_0_arm64.whl (11.0 MB) ---------> this ends up 51 MB

Collecting scipy
  Using cached scipy-1.13.1-cp311-cp311-macosx_12_0_arm64.whl (30.3 MB)

Collecting aiosignal>=1.1.2
  Using cached aiosignal-1.3.1-py3-none-any.whl (7.6 kB)
Collecting attrs>=17.3.0
  Using cached attrs-23.2.0-py3-none-any.whl (60 kB)
Collecting frozenlist>=1.1.1
  Using cached frozenlist-1.4.1-cp311-cp311-macosx_11_0_arm64.whl (53 kB)
Collecting multidict<7.0,>=4.5
  Using cached multidict-6.0.5-cp311-cp311-macosx_11_0_arm64.whl (30 kB)
Collecting yarl<2.0,>=1.0
  Using cached yarl-1.9.4-cp311-cp311-macosx_11_0_arm64.whl (81 kB)
Collecting pydantic>=1.10
  Using cached pydantic-2.7.2-py3-none-any.whl (409 kB)
Collecting anyio
  Using cached anyio-4.4.0-py3-none-any.whl (86 kB)
Collecting certifi
  Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)
Collecting httpcore==1.*
  Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)
Collecting idna
  Using cached idna-3.7-py3-none-any.whl (66 kB)
Collecting sniffio
  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)
Collecting h11<0.15,>=0.13
  Using cached h11-0.14.0-py3-none-any.whl (58 kB)
Collecting click
  Using cached click-8.1.7-py3-none-any.whl (97 kB)
Collecting joblib
  Using cached joblib-1.4.2-py3-none-any.whl (301 kB)
Collecting regex>=2021.8.3
  Using cached regex-2024.5.15-cp311-cp311-macosx_11_0_arm64.whl (278 kB)
Collecting distro<2,>=1.7.0
  Using cached distro-1.9.0-py3-none-any.whl (20 kB)
Collecting charset-normalizer<4,>=2
  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)
Collecting urllib3<3,>=1.21.1
  Using cached urllib3-2.2.1-py3-none-any.whl (121 kB)
Collecting greenlet!=0.4.17
  Using cached greenlet-3.0.3-cp311-cp311-macosx_11_0_universal2.whl (271 kB)
Collecting sympy
  Downloading sympy-1.12.1-py3-none-any.whl (5.7 MB)
Collecting jinja2
  Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)
Collecting tokenizers<0.20,>=0.19
  Using cached tokenizers-0.19.1-cp311-cp311-macosx_11_0_arm64.whl (2.4 MB)
Collecting safetensors>=0.4.1
  Using cached safetensors-0.4.3-cp311-cp311-macosx_11_0_arm64.whl (410 kB)
Collecting mypy-extensions>=0.3.0
  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)
Collecting marshmallow<4.0.0,>=3.18.0
  Using cached marshmallow-3.21.2-py3-none-any.whl (49 kB)
Collecting python-dateutil>=2.8.2
  Using cached python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)
Collecting pytz>=2020.1
  Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)
Collecting tzdata>=2022.7
  Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)
Collecting threadpoolctl>=3.1.0
  Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)
Collecting annotated-types>=0.4.0
  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)
Collecting pydantic-core==2.18.3
  Using cached pydantic_core-2.18.3-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)
Collecting six>=1.5
  Using cached six-1.16.0-py2.py3-none-any.whl (11 kB)
Collecting MarkupSafe>=2.0
  Using cached MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl (18 kB)
Collecting mpmath<1.4.0,>=1.1.0
  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)

Installing collected packages: pytz, mpmath, dirtyjson, wrapt, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, tenacity, sympy, sniffio,
six, safetensors, regex, pyyaml, pillow, packaging, numpy, networkx, nest-asyncio, mypy-extensions, multidict, minijinja, MarkupSafe, joblib, idna,
h11, greenlet, fsspec, frozenlist, filelock, distro, click, charset-normalizer, certifi, attrs, annotated-types, yarl, typing-inspect, SQLAlchemy,
scipy, requests, python-dateutil, pydantic-core, nltk, marshmallow, jinja2, httpcore, deprecated, anyio, aiosignal, torch, tiktoken, scikit-learn,
pydantic, pandas, huggingface-hub, httpx, dataclasses-json, aiohttp, tokenizers, openai, llamaindex-py-client, transformers, llama-index-core,
sentence-transformers, llama-index-embeddings-huggingface

-------------------------------------------------

TOTAL lib folder: 947 MB

-------------------------------------------------

from llama_index.embeddings.huggingface import HuggingFaceEmbedding
embed_model = HuggingFaceEmbedding(model_name="hkunlp/instructor-xl")

modules.json:                       100%| 461/461 [00:00<00:00, 1.56MB/s]
config_sentence_transformers.json:  100%| 122/122 [00:00<00:00, 450kB/s]
README.md:                          100%| 66.3k/66.3k [00:00<00:00, 3.23MB/s]
sentence_bert_config.json:          100%| 53.0/53.0 [00:00<00:00, 146kB/s]
.venv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed.
config.json:                        100%| 1.52k/1.52k [00:00<00:00, 5.24MB/s]
pytorch_model.bin:                  100%| 4.96G/4.96G [08:37<00:00, 9.60MB/s]
tokenizer_config.json:              100%| 2.40k/2.40k [00:00<00:00, 9.71MB/s]
spiece.model:                       100%| 792k/792k [00:00<00:00, 2.21MB/s]
tokenizer.json:                     100%| 2.42M/2.42M [00:00<00:00, 3.01MB/s]
special_tokens_map.json:            100%| 2.20k/2.20k [00:00<00:00, 7.73MB/s]
1_Pooling/config.json:              100%| 270/270 [00:00<00:00, 978kB/s]
2_Dense/config.json:                100%| 116/116 [00:00<00:00, 410kB/s]
pytorch_model.bin:                  100%| 3.15M/3.15M [00:00<00:00, 8.01MB/s]

-------------------------------------------------

https://github.com/run-llama/llama_index/issues/11047 -- Offline use of embed_model
https://github.com/run-llama/llama_index/blob/main/llama-index-core/llama_index/core/embeddings/utils.py

from llama_index.core.utils import get_cache_dir
get_cache_dir() --> '~/Library/Caches/llama_index'

-------------------------------------------------
-------------------------------------------------
-------------------------------------------------

pip install llama-index

striprtf, pytz, dirtyjson, wrapt, urllib3, tzdata, typing-extensions, tqdm, tenacity, soupsieve, sniffio, six, regex, PyYAML, pypdf, pillow,
packaging, numpy, networkx, nest-asyncio, mypy-extensions, multidict, joblib, idna, h11, greenlet, fsspec, frozenlist, distro, click,
charset-normalizer, certifi, attrs, annotated-types, yarl, typing-inspect, SQLAlchemy, requests, python-dateutil, pydantic-core, nltk,
marshmallow, httpcore, deprecated, beautifulsoup4, anyio, aiosignal, tiktoken, pydantic, pandas, httpx, dataclasses-json, aiohttp, openai,
llamaindex-py-client, llama-index-legacy, llama-index-core, llama-parse, llama-index-readers-file, llama-index-llms-openai,
llama-index-indices-managed-llama-cloud, llama-index-embeddings-openai, llama-index-readers-llama-parse, llama-index-multi-modal-llms-openai,
llama-index-cli, llama-index-agent-openai, llama-index-program-openai, llama-index-question-gen-openai, llama-index
